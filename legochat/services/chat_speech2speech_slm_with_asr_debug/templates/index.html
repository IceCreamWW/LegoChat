<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Voice Chat App with Microphone Waveform Animation</title>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="./{{ url_for('static', filename='bootstrap.min.css') }}">
  <link rel="stylesheet" href="./{{ url_for('static', filename='all.min.css') }}">
  <link rel="stylesheet" href="./{{ url_for('static', filename='bg.css') }}">
  <link rel="stylesheet" href="./{{ url_for('static', filename='style.css') }}">
</head>
<body>
  <div class="chat-container relative mx-auto w-100 h-100 max-w-full overflow-hidden bg-gradient-to-br from-[--color-a] via-[--color-b] to-[--color-c] text-white duration-500 ease-in [transition-property:_--color-a,_--color-b,_--color-c] before:absolute before:left-[20%] before:top-[10%] before:h-[50%] before:w-[70%] before:origin-[60%] before:animate-blob before:bg-gradient-to-br before:from-[--color-a] before:to-[--color-b] before:blur-[50px] before:brightness-125 after:absolute after:left-[40%] after:top-[30%] after:h-[80%] after:w-[70%] after:origin-[60%] after:animate-blob-reverse after:bg-gradient-to-br after:from-[--color-a] after:to-[--color-b] after:blur-[50px] after:brightness-125" style="--color-a: rgb(51, 153, 255, 0.3); --color-b: rgb(244, 229, 77, 0.3); --color-c: rgb(255, 170, 51, 0.3)">
    <div class="d-flex mx-auto justify-content-between aspect-[9/16] flex-column mw-100 mh-100">
    <!-- <div class="logo" id="logo"> <img src="./{{ url_for('static', filename='logo.png') }}"/> </div> -->
      <!-- Transcript section -->
      <div class="transcript" id="transcript">
        <p><strong>User:</strong> Hello!</p>
        <p><strong>Agent:</strong> Hi there, how can I help?</p>
      </div>
      <!-- Transcript toggle icon -->
      <div class="transcript-toggle" id="transcriptToggle">
        <i class="fas fa-comments"></i>
      </div>
      <!-- Center animated circle -->
      <div class="circle mx-auto w-75" id="agentCircle">
          <div class="background-moving"></div>
          <div class="avatar"><img id="agentAvatar" src="./{{url_for('static', filename='agent_avatar/default.png')}}"/></div>
      </div>
      <!-- New call button (green) -->
      <div class="px-4 py-5 w-100 flex items-center justify-center" id="idleControls">
        <button class="call-btn w-25" id="newCallBtn">
          <i class="fas fa-phone fa-fw"></i>
        </button>
      </div>

      <div class="px-4 py-5 w-100 d-flex justify-content-between d-none" id="chatControls">
      <!-- Hangup button (red) -->
        <button class="hangup-btn w-25" id="hangupBtn">
          <i class="fas fa-xmark fa-fw"></i>
        </button>
        <div class="d-flex flex-column justify-content-around">
          <div class="d-flex justify-content-center" id="micViz">
            <div></div>
            <div></div>
            <div></div>
          </div>
          <div class="status-text" id="statusText">Listening</div>
        </div>
        <!-- Microphone toggle button -->
        <button class="mic-toggle-btn w-25" id="micToggleBtn">
          <i class="fas fa-microphone fa-fw"></i>
        </button>
      </div>
    </div>
    <!-- Animated voice dots -->
  </div>

  <!-- jQuery and Bootstrap JS (for simplicity) -->
  <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
  <script src="./{{url_for('static', filename='bootstrap.min.js')}}"></script>
  <!-- Include hls.js via CDN -->
  <script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
  <script>
    let analyser;
    let dataArray;
    let microphoneStream;
    let animationFrameId;
    let sessionId = '';
    let audioContext, mediaStream, audioSource, processor, agentAudio;
    let agentCanSpeak = false;
    let isSessionStarted = false;
    let isListening = true;
    let pollingActive = true;
    let agentSpekaer = "default";
    let speaker2avatar = {
      "default": "./{{url_for('static', filename='agent_avatar/default.png')}}",
      "female": "./{{url_for('static', filename='agent_avatar/female.png')}}",
      "male": "./{{url_for('static', filename='agent_avatar/male.png')}}",
      "nezha": "./{{url_for('static', filename='agent_avatar/nezha.png')}}",
      "taiyi": "./{{url_for('static', filename='agent_avatar/taiyi.png')}}",
      "aobing": "./{{url_for('static', filename='agent_avatar/aobing.png')}}",
      "self": "./{{url_for('static', filename='agent_avatar/logo.png')}}",
    }

    class AudioVisualizer {
      constructor(audioContext, processFrame, processError, stream) {
        this.audioContext = audioContext;
        this.processFrame = processFrame;
        this.connectStream = this.connectStream.bind(this);
        // navigator.mediaDevices.getUserMedia({ audio: true, video: false }).
        // then(this.connectStream).
        try {
          this.connectStream(stream);
        } catch (e) {
          processError();
        }
      }

      connectStream(stream) {
        this.analyser = this.audioContext.createAnalyser();
        const source = this.audioContext.createMediaStreamSource(stream);
        source.connect(this.analyser);
        this.analyser.smoothingTimeConstant = 0.5;
        this.analyser.fftSize = 32;

        this.initRenderLoop(this.analyser);
      }

      initRenderLoop() {
        const frequencyData = new Uint8Array(this.analyser.frequencyBinCount);
        const processFrame = this.processFrame || (() => {});

        const renderFrame = () => {
          this.analyser.getByteFrequencyData(frequencyData);
          processFrame(frequencyData);

          requestAnimationFrame(renderFrame);
        };
        requestAnimationFrame(renderFrame);
      }
    }

    $(document).ready(function() {
      // Toggle transcript display when the transcript icon is clicked
      $('#transcriptToggle').click(function() {
        $('#transcript').toggle();
      });

      // On new call button click: start microphone capture and animation
      $('#newCallBtn').click(function() {
        $('#idleControls').addClass('d-none');
        $('#chatControls').removeClass('d-none');
        startSession();
      });

      // On hangup button click: stop microphone capture and reset UI
      $('#hangupBtn').click(function() {
        if (agentAudio) {
          agentAudio.pause();
          agentCanSpeak = false;
        }

        $('#chatControls').addClass('d-none');
        $('#idleControls').removeClass('d-none');
        // Reset UI elements
        $('#agentCircle').css('transform', 'scale(.9)');
        stopSession();
      });

      // Toggle microphone button to simulate mute/unmute (UI only)
      $('#micToggleBtn').click(function() {
        isListening = !isListening;
        $(this).toggleClass('muted');
        if($(this).hasClass('muted')) {
          $(this).html('<i class="fas fa-microphone-slash"></i>');
          $(this).css('color', '#FE3A2E');
        } else {
          $(this).html('<i class="fas fa-microphone"></i>');
          $(this).css('color', 'black');
        }
      });
    });

    // Start capturing microphone audio
    function startAudio() {
      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ audio: true, video: false })
          .then(function(stream) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            microphoneStream = stream;
            const source = audioContext.createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            source.connect(analyser);
            dataArray = new Uint8Array(analyser.frequencyBinCount);
            updateAnimation();
          })
          .catch(function(err) {
            console.error("Error accessing microphone: " + err);
          });
      } else {
        alert("getUserMedia not supported in this browser.");
      }
    }

    // Stop capturing audio and cancel the animation loop
    function stopAudio() {
      if (microphoneStream) {
        microphoneStream.getTracks().forEach(track => track.stop());
      }
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
      analyser = null;
    }

    async function stopSession() {
      if (! isSessionStarted) return;
      isSessionStarted = false;
      if (processor && audioSource) {
          audioSource.disconnect(processor);
          processor.disconnect();
      }
      analyser = null;
    }

    async function startSession() {
        if (isSessionStarted) return; 
        isSessionStarted = true;

        // Initialize AudioContext
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });

        // Resume AudioContext if suspended
        if (audioContext.state === 'suspended') {
            await audioContext.resume();
        }

        const sampleRate = audioContext.sampleRate;
        const response = await fetch(`./start_session?allow_vad_interrupt=true&sample_rate=16000`);
        const responseData = await response.json();
        sessionId = responseData.session_id;

        await initializeAudio();
        visualizeMicrophone();
        // visualizeAgent(audioContext, mediaStream);
        pollTranscript();
    }



  function visualizeMicrophone() {
    const visualValueCount = 3;
    let visualElements = document.querySelectorAll('#micViz div');
    const init = () => {
      const dataMap = { 0: 8, 1: 10, 2: 9};
      const processFrame = data => {
        const values = Object.values(data);
        let i;
        for (i = 0; i < visualValueCount; ++i) {
          const value = Math.min(3, values[dataMap[i]] / 255 * 5 + 1);
          const elmStyles = visualElements[i].style;
          elmStyles.transform = `scaleY( ${value} )`;
          // elmStyles.opacity = Math.max(.25, value);
        }
      };
      const processError = () => {
        visualMainElement.classList.add('error');
        visualMainElement.innerText = 'Please allow access to your microphone in order to see this demo.\nNothing bad is going to happen... hopefully :P';
      };
      const a = new AudioVisualizer(audioContext, processFrame, processError, mediaStream);
    }
    init();
  };

  function visualizeAgent(agentAudioContext, agentMeidaStream) {
    let visualElement = document.querySelector('#agentCircle');
    const init = () => {
      const processFrame = data => {
        const elmStyles = visualElement.style;
        if (!agentCanSpeak) {
          elmStyles.transform = "scale(0.9)";
          return;
        };
        const values = Object.values(data);
        const value = Math.max(0.7, .9 - values[0] / 2 / 255)
        elmStyles.transform = `scale( ${value} )`;
      };
      const processError = () => {
        visualMainElement.classList.add('error');
        visualMainElement.innerText = 'Please allow access to your microphone in order to see this demo.\nNothing bad is going to happen... hopefully :P';
      };
      // const a = new AudioVisualizer(audioContext, processFrame, processError, agentMeidaStream);
      const a = new AudioVisualizer(audioContext, processFrame, processError, mediaStream);
    }
    init();
  };

    async function initializeAudio() {
        // Start microphone stream
        try {
            mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (error) {
            alert('Microphone access denied.');
            console.error('Error accessing microphone:', error);
            return;
        }

        audioSource = audioContext.createMediaStreamSource(mediaStream);

        // Create a processor node
        processor = audioContext.createScriptProcessor(4096, 1, 1);
        audioSource.connect(processor);

        // Queue to hold audio data
        let audioQueue = [];
        let isProcessing = false;

        // Function to send audio data without blocking
        async function sendAudioData() {
            while (audioQueue.length > 0) {
                const data = audioQueue.shift();
                try {
                    await fetch(`./${sessionId}/user_audio`, {
                        method: 'POST',
                        body: data
                    });
                } catch (error) {
                    console.error('Error sending audio data:', error);
                }
            }
        }

        // Processor callback for audio data
        processor.onaudioprocess = function(event) {
            if (!isListening) return; // Do nothing if not listening

            const audioData = event.inputBuffer.getChannelData(0);
            const int16Data = new Int16Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
                int16Data[i] = audioData[i] * 32767;
            }
            const binaryData = new Uint8Array(int16Data.buffer);

            // Add data to queue
            audioQueue.push(binaryData);

            // Process audio data asynchronously
            if (!isProcessing) {
                isProcessing = true;
                sendAudioData().finally(() => {
                    isProcessing = false;
                });
            }
        };

        processor.connect(audioContext.destination); // Connect to avoid garbage collection
        // Start polling for agent's ability to speak
        pollAgentCanSpeak();
    }
    async function pollAgentCanSpeak() {
        let audio = new Audio();
        agentAudio = audio;
        audio.loop = false;
        let hls;

        audio.addEventListener('ended', async () => {
            await fetch(`./${sessionId}/agent_finished_speaking`, { method: 'POST' });
        });

        const intervalId = setInterval(async () => {
            if (!pollingActive) {
                clearInterval(intervalId);
                return;
            }

            try {
                const response = await fetch(`./${sessionId}/agent_can_speak`);
                if (!response.ok) throw new Error('Network response was not ok');
                let { agent_can_speak } = await response.json();

                if (agent_can_speak && !agentCanSpeak) {
                    const m3u8Url = `./${sessionId}/assets/agent.m3u8?time=${Date.now()}`;
                    if (Hls.isSupported()) {
                        if (hls) {
                            hls.destroy();
                        }
                        hls = new Hls({ startPosition: 0 });
                        hls.loadSource(m3u8Url);
                        hls.attachMedia(audio);
                        hls.on(Hls.Events.MANIFEST_PARSED, function () {
                            const agentMeidaStream = audio.captureStream();
                            visualizeAgent(audioContext, agentMeidaStream);
                            audio.currentTime = 0;
                            audio.play();
                        });
                    } else if (audio.canPlayType('application/vnd.apple.mpegurl')) {
                        audio.src = m3u8Url;
                        audio.play();
                    } else {
                        console.error('This browser does not support HLS.');
                    }
                } else if (!agent_can_speak && agentCanSpeak) {
                    if (hls) {
                        hls.destroy();
                        hls = null;
                    }
                    audio.pause();
                    audio.currentTime = 0;
                    audio.src = '';
                }

                agentCanSpeak = agent_can_speak;

                if (!$('#micToggleBtn').hasClass("muted")) {
                  if (agentCanSpeak) {
                      $("#statusText").html("Speaking");
                  } else {
                      $("#statusText").html("Listening");
                  }
                }
            } catch (error) {
                console.error('Error fetching agent_can_speak:', error);
                pollingActive = false;
                showLostConnectionOverlay();
            }

            try {
                const response = await fetch(`./${sessionId}/agent_speaker`);
                if (!response.ok) throw new Error('Network response was not ok');
                let { agent_speaker } = await response.json();
                if (agent_speaker !== agentSpekaer) {
                    agentSpekaer = agent_speaker;
                    const avatarSrc = speaker2avatar[agent_speaker];
                    if (avatarSrc) {
                        $('#agentAvatar').attr('src', avatarSrc);
                    } else {
                        console.error(`No avatar found for speaker: ${agent_speaker}`);
                    }
                  console.log(agent_speaker);
                }
            } catch (error) {
                console.error('Error fetching transcript:', error);
                pollingActive = false;
                showLostConnectionOverlay();
            }
        }, 100);
    }


    async function pollTranscript() {
        const intervalId = setInterval(async () => {
            if (!pollingActive) {
                clearInterval(intervalId);
                return;
            }

            try {
                const response = await fetch(`./${sessionId}/transcript`);
                if (!response.ok) throw new Error('Network response was not ok');
                const transcript = await response.json();
                console.log(transcript);
            } catch (error) {
                console.error('Error fetching transcript:', error);
                pollingActive = false;
                showLostConnectionOverlay();
            }
        }, 1000);
    }

    async function showLostConnectionOverlay() {
        if (processor && audioSource) {
            audioSource.disconnect(processor);
            processor.disconnect();
        }
        alert("connection lost")
    }

  </script>
</body>



