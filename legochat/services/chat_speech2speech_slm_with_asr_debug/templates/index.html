<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Voice Chat App with Microphone Waveform Animation</title>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="./{{ url_for('static', filename='bootstrap.min.css') }}">
  <link rel="stylesheet" href="./{{ url_for('static', filename='font-awesome/css/all.min.css') }}">
  <link rel="stylesheet" href="./{{ url_for('static', filename='bg.css') }}">
  <link rel="stylesheet" href="./{{ url_for('static', filename='style.css') }}">
</head>
<body>
  <div class="chat-container relative mx-auto w-100 h-100 max-w-full overflow-hidden bg-gradient-to-br from-[--color-a] via-[--color-b] to-[--color-c] text-white duration-500 ease-in [transition-property:_--color-a,_--color-b,_--color-c] before:absolute before:left-[20%] before:top-[10%] before:h-[50%] before:w-[70%] before:origin-[60%] before:animate-blob before:bg-gradient-to-br before:from-[--color-a] before:to-[--color-b] before:blur-[50px] before:brightness-125 after:absolute after:left-[40%] after:top-[30%] after:h-[80%] after:w-[70%] after:origin-[60%] after:animate-blob-reverse after:bg-gradient-to-br after:from-[--color-a] after:to-[--color-b] after:blur-[50px] after:brightness-125" style="--color-a: rgb(51, 153, 255, 0.3); --color-b: rgb(244, 229, 77, 0.3); --color-c: rgb(255, 170, 51, 0.3)">
    <div class="d-flex mx-auto justify-content-between aspect-[9/16] flex-column mw-100 mh-100">
    <!-- <div class="logo" id="logo"> <img src="./{{ url_for('static', filename='logo.png') }}"/> </div> -->
      <!-- Transcript section -->
      <div class="transcript" id="transcript">
        <p><strong>User:</strong> Hello!</p>
        <p><strong>Agent:</strong> Hi there, how can I help?</p>
      </div>
      <!-- Transcript toggle icon -->
      <div class="transcript-toggle" id="transcriptToggle">
        <i class="fas fa-comments"></i>
      </div>
      <!-- Center animated circle -->
      <div class="circle mx-auto w-75" id="agentCircle">
          <div class="background-moving"></div>
          <div class="avatar"><img id="agentAvatar" src="./{{url_for('static', filename='agent_avatar/default.png')}}"/></div>
      </div>
      <!-- New call button (green) -->
      <div class="px-4 py-5 w-100 flex items-center justify-center" id="idleControls">
        <button class="call-btn w-25" id="newCallBtn">
          <i class="fas fa-phone fa-fw"></i>
        </button>
      </div>

      <div class="px-4 py-5 w-100 d-flex justify-content-between d-none" id="chatControls">
      <!-- Hangup button (red) -->
        <button class="hangup-btn w-25" id="hangupBtn">
          <i class="fas fa-xmark fa-fw"></i>
        </button>
        <div class="d-flex flex-column justify-content-around">
          <div class="d-flex justify-content-center" id="micViz">
            <div></div>
            <div></div>
            <div></div>
          </div>
          <div class="status-text" id="statusText">Listening</div>
        </div>
        <!-- Microphone toggle button -->
        <button class="mic-toggle-btn w-25" id="micToggleBtn">
          <i class="fas fa-microphone fa-fw"></i>
        </button>
      </div>
    </div>
    <!-- Animated voice dots -->
  </div>

  <!-- jQuery and Bootstrap JS (for simplicity) -->
  <script src="./{{url_for('static', filename='jquery-3.5.1.min.js')}}"></script>
  <script src="./{{url_for('static', filename='bootstrap.min.js')}}"></script>
  <!-- Include hls.js via CDN -->
  <script src="./{{url_for('static', filename='hls.js')}}"></script>
  <script>
    let microphoneStream;
    let animationFrameId;
    let sessionId = '';
    let audioContext, mediaStream, audioSource, processor;
    let agentCanSpeak = false;
    let isSessionStarted = false;
    let isListening = true;
    let agentSpeaker = "default";
    let connectionIsAlive = 10;
    let speaker2avatar = {
      "default": "./{{url_for('static', filename='agent_avatar/default.png')}}",
      "female": "./{{url_for('static', filename='agent_avatar/female.png')}}",
      "male": "./{{url_for('static', filename='agent_avatar/male.png')}}",
      "nezha": "./{{url_for('static', filename='agent_avatar/nezha.png')}}",
      "taiyi": "./{{url_for('static', filename='agent_avatar/taiyi.png')}}",
      "aobing": "./{{url_for('static', filename='agent_avatar/aobing.png')}}",
      "child": "./{{url_for('static', filename='agent_avatar/child.png')}}",
      "self": "./{{url_for('static', filename='agent_avatar/logo.png')}}",
    }
    let agentAudio, hls;
    class AudioVisualizer {
      constructor(audioContext, processFrame, processError, stream) {
        this.audioContext = audioContext;
        this.processFrame = processFrame;
        this.connectStream = this.connectStream.bind(this);
        // navigator.mediaDevices.getUserMedia({ audio: true, video: false }).
        // then(this.connectStream).
        try {
          this.connectStream(stream);
        } catch (e) {
          processError();
        }
      }

      connectStream(stream) {
        this.analyser = this.audioContext.createAnalyser();
        const source = this.audioContext.createMediaStreamSource(stream);
        source.connect(this.analyser);
        this.analyser.smoothingTimeConstant = 0.5;
        this.analyser.fftSize = 32;

        this.initRenderLoop(this.analyser);
      }

      initRenderLoop() {
        const frequencyData = new Uint8Array(this.analyser.frequencyBinCount);
        const processFrame = this.processFrame || (() => {});

        const renderFrame = () => {
          this.analyser.getByteFrequencyData(frequencyData);
          processFrame(frequencyData);

          requestAnimationFrame(renderFrame);
        };
        requestAnimationFrame(renderFrame);
      }
    }

    $(document).ready(function() {
      agentAudio = new Audio();;
      agentAudio.loop = false;
      agentAudio.addEventListener('ended', async () => {
        await fetch(`./${sessionId}/agent_finished_speaking`, { method: 'POST' });
      });

      // Toggle transcript display when the transcript icon is clicked
      $('#transcriptToggle').click(function() {
        $('#transcript').toggle();
      });

      // On new call button click: start microphone capture and animation
      $('#newCallBtn').click(function() {
        $('#idleControls').addClass('d-none');
        $('#chatControls').removeClass('d-none');
        startSession();
      });
      // On hangup button click: stop microphone capture and reset UI
      $('#hangupBtn').click(async function() {
        agentAudio.pause()
        $('#chatControls').addClass('d-none');
        $('#idleControls').removeClass('d-none');
        $('#agentCircle').css('transform', 'scale(.9)');
        stopSession();
      });

      // Toggle microphone button to simulate mute/unmute (UI only)
      $('#micToggleBtn').click(function() {
        isListening = !isListening;
        $(this).toggleClass('muted');
        if($(this).hasClass('muted')) {
          $(this).html('<i class="fas fa-microphone-slash"></i>');
          $(this).css('color', '#FE3A2E');
        } else {
          $(this).html('<i class="fas fa-microphone"></i>');
          $(this).css('color', 'black');
        }
      });
    });

    // Stop capturing audio and cancel the animation loop
    function stopAudio() {
      if (microphoneStream) {
        microphoneStream.getTracks().forEach(track => track.stop());
      }
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
    }

    async function stopSession() {
      if (! isSessionStarted) return;
      isSessionStarted = false;
      if (processor && audioSource) {
          audioSource.disconnect(processor);
          processor.disconnect();
      }
    }

    async function startSession() {
        if (isSessionStarted) return; 
        isSessionStarted = true;

        // Initialize AudioContext
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });

        // Resume AudioContext if suspended
        if (audioContext.state === 'suspended') {
            await audioContext.resume();
        }

        const sampleRate = audioContext.sampleRate;
        const response = await fetch(`./start_session?allow_vad_interrupt=true&sample_rate=16000`);
        const responseData = await response.json();
        sessionId = responseData.session_id;

        await initializeAudio();
        visualizeMicrophone();
    }



  function visualizeMicrophone() {
    const visualValueCount = 3;
    let visualElements = document.querySelectorAll('#micViz div');
    const init = () => {
      const dataMap = { 0: 8, 1: 10, 2: 9};
      const processFrame = data => {
        const values = Object.values(data);
        let i;
        for (i = 0; i < visualValueCount; ++i) {
          const value = Math.min(3, values[dataMap[i]] / 255 * 5 + 1);
          const elmStyles = visualElements[i].style;
          if (!$('#micToggleBtn').hasClass("muted")) {
            elmStyles.transform = `scaleY( ${value} )`;
          } else {
            elmStyles.transform = `scaleY( 1 )`;
          }
          // elmStyles.opacity = Math.max(.25, value);
        }
      };
      const processError = () => {
        visualMainElement.classList.add('error');
        visualMainElement.innerText = 'Please allow access to your microphone in order to see this demo.\nNothing bad is going to happen... hopefully :P';
      };
      const a = new AudioVisualizer(audioContext, processFrame, processError, mediaStream);
    }
    init();
  };

  function visualizeAgent(agentAudioContext, agentMeidaStream) {
    let visualElement = document.querySelector('#agentCircle');
    const init = () => {
      const processFrame = data => {
        const elmStyles = visualElement.style;
        if (!agentCanSpeak || !isSessionStarted) {
          elmStyles.transform = "scale(0.9)";
          return;
        };
        const values = Object.values(data);
        const value = Math.max(0.7, .9 - values[0] / 2 / 255)
        elmStyles.transform = `scale( ${value} )`;
      };
      const processError = () => {
        visualMainElement.classList.add('error');
        visualMainElement.innerText = 'Please allow access to your microphone in order to see this demo.\nNothing bad is going to happen... hopefully :P';
      };
      // const a = new AudioVisualizer(audioContext, processFrame, processError, agentMeidaStream);
      const a = new AudioVisualizer(audioContext, processFrame, processError, mediaStream);
    }
    init();
  };

    async function initializeAudio() {
        // Start microphone stream
        try {
            mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (error) {
            alert('Microphone access denied.');
            console.error('Error accessing microphone:', error);
            return;
        }

        audioSource = audioContext.createMediaStreamSource(mediaStream);

        // Create a processor node
        processor = audioContext.createScriptProcessor(4096, 1, 1);
        audioSource.connect(processor);

        // Queue to hold audio data
        let audioQueue = [];
        let isProcessing = false;

        // Function to send audio data without blocking
        async function sendAudioData() {
          if (!connectionIsAlive) return;
          while (audioQueue.length > 0) {
              const data = audioQueue.shift();
              try {
                  response = await fetch(`./${sessionId}/user_audio`, {
                      method: 'POST',
                      body: data
                  });
                  if (!response.ok) {
                      throw new Error('Network response was not ok');
                  }
                  let {transcript, total_sessions, agent_speaker, agent_can_speak} = await response.json();
                  await agentSpeakerHandler(agent_speaker);
                  await agentCanSpeakHandler(agent_can_speak);
                  connectionIsAlive = 10;
              } catch (error) {
                connectionIsAlive -= 1;
                if (connectionIsAlive <= 0) {
                  showLostConnectionOverlay();
                }
              }
          }
        }

        async function agentSpeakerHandler(agent_speaker) {
            if (agent_speaker !== agentSpeaker) {
                agentSpeaker = agent_speaker;
                const avatarSrc = speaker2avatar[agent_speaker];
                if (avatarSrc) {
                    $('#agentAvatar').attr('src', avatarSrc);
                } else {
                    console.error(`No avatar found for speaker: ${agent_speaker}`);
                }
            }
        }

        async function agentCanSpeakHandler(agent_can_speak) {
          if (agent_can_speak && !agentCanSpeak) {
              const m3u8Url = `./${sessionId}/assets/agent.m3u8?time=${Date.now()}`;
              if (Hls.isSupported()) {
                  if (hls) {
                      hls.destroy();
                  }
                  hls = new Hls({ startPosition: 0 });
                  hls.loadSource(m3u8Url);
                  hls.attachMedia(agentAudio);
                  hls.on(Hls.Events.MANIFEST_PARSED, function () {
                    agentAudio.currentTime = 0;
                    const agentMeidaStream = agentAudio.captureStream();
                    visualizeAgent(audioContext, agentMeidaStream);
                    agentAudio.play();
                  });
              } else if (agentAudio.canPlayType('application/vnd.apple.mpegurl')) {
                  agentAudio.src = m3u8Url;
                  agentAudio.play();
              } else {
                  console.error('This browser does not support HLS.');
              }
          } else if (!agent_can_speak && agentCanSpeak) {
              if (hls) {
                  hls.destroy();
                  hls = null;
              }
              agentAudio.pause();
              agentAudio.currentTime = 0;
              agentAudio.src = '';
          }

          agentCanSpeak = agent_can_speak;

          if (agentCanSpeak) {
              $("#statusText").html("Speaking");
          } else {
            if (!$('#micToggleBtn').hasClass("muted")) {
              $("#statusText").html("Listening");
            } else {
              $("#statusText").html("Muted");
            }
          }
        }

        // Processor callback for audio data
        processor.onaudioprocess = function(event) {
          let binaryData;
          if (!isListening) {
            const silence = new Int16Array(1024);
            binaryData = new Uint8Array(silence.buffer);
          } else {
            const audioData = event.inputBuffer.getChannelData(0);
            const int16Data = new Int16Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
                int16Data[i] = audioData[i] * 32767;
            }
            binaryData = new Uint8Array(int16Data.buffer);
          }

          audioQueue.push(binaryData);
          if (!isProcessing) {
              isProcessing = true;
              sendAudioData().finally(() => {
                  isProcessing = false;
              });
          }
        };

        processor.connect(audioContext.destination); // Connect to avoid garbage collection
    }
    async function pollAgentCanSpeak() {

        const intervalId = setInterval(async () => {
        }, 100);
    }

    async function showLostConnectionOverlay() {
        if (processor && audioSource) {
            audioSource.disconnect(processor);
            processor.disconnect();
        }
        alert("connection lost")
    }

  </script>
</body>
